{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c130a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from IPython.display import display, HTML\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "from datasets.Waymo import WaymoDataset, waymo_collate_fn\n",
    "from model import OccupancyFlowNetwork\n",
    "from visualize import render_observed_scene_state, render_ground_truth_occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dcfab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SCENES = 25#25\n",
    "MAX_SCENES_TO_RENDER = 1\n",
    "\n",
    "tfrecord_path = '../../data1/waymo_dataset/v1.1/waymo_open_dataset_motion_v_1_1_0/uncompressed/tf_example/validation'\n",
    "idx_path = '../../data1/waymo_dataset/v1.1/idx/validation'\n",
    "dataset = WaymoDataset(tfrecord_path, idx_path)\n",
    "dataloader = DataLoader(dataset, batch_size=NUM_SCENES, collate_fn=waymo_collate_fn)\n",
    "\n",
    "scenes = []\n",
    "#for _ in range(NUM_SCENES):\n",
    "scenes.append(next(iter(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7037fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for scene in scenes:\n",
    "    road_map = scene.observed_state.road_map\n",
    "    agent_trajectories = scene.observed_state.agent_trajectories\n",
    "\n",
    "    count += 1\n",
    "    if count > MAX_SCENES_TO_RENDER:\n",
    "        break\n",
    "\n",
    "render_observed_scene_state(road_map[0], agent_trajectories[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9afc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for scene in scenes:\n",
    "    road_map = scene.observed_state.road_map\n",
    "    occupancy_grid_occupancies = scene.occupancy_grid.unoccluded_occupancies\n",
    "\n",
    "    count += 1\n",
    "    if count > MAX_SCENES_TO_RENDER:\n",
    "        break\n",
    "\n",
    "    anim = render_ground_truth_occupancy(road_map[0], occupancy_grid_occupancies[0])\n",
    "    display(HTML(anim.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65400ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for scene in scenes:\n",
    "    road_map = scene.observed_state.road_map\n",
    "    occupancy_grid_occluded_occupancies = scene.occupancy_grid.occluded_occupancies\n",
    "\n",
    "    count += 1\n",
    "    if count > MAX_SCENES_TO_RENDER:\n",
    "        break\n",
    "\n",
    "    anim = render_ground_truth_occupancy(road_map[0], occupancy_grid_occluded_occupancies[0], occluded=True)\n",
    "    display(HTML(anim.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac86bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16077ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for scene in scenes:\n",
    "    count += 1\n",
    "    if count > MAX_SCENES_TO_RENDER:\n",
    "        break\n",
    "\n",
    "    road_map = scene.observed_state.road_map\n",
    "\n",
    "    anim = render_ground_truth_occupancy(road_map[0], estimated_occupancies[0].cpu(), occluded=False)\n",
    "    display(HTML(anim.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ff20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_flow_network = OccupancyFlowNetwork(road_map_image_size=256, road_map_window_size=8, \n",
    "                                              trajectory_feature_dim=10, \n",
    "                                              embedding_dim=256, \n",
    "                                              flow_field_hidden_dim=256, flow_field_fourier_features=0).to(device)\n",
    "occupancy_flow_network.train()\n",
    "\n",
    "optim = torch.optim.Adam(occupancy_flow_network.parameters(), lr=1e-4, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.999)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "EPOCHS = 10000\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for scene in scenes:\n",
    "        road_map = scene.observed_state.road_map.to(device)\n",
    "        agent_trajectories = scene.observed_state.agent_trajectories.to(device)\n",
    "        occupancy_grid_positions = scene.occupancy_grid.positions.to(device)\n",
    "        occupancy_grid_times = scene.occupancy_grid.times.to(device)\n",
    "        occupancy_grid_unoccluded_occupancies = scene.occupancy_grid.unoccluded_occupancies.to(device)\n",
    "        occupancy_grid_occluded_occupancies = scene.occupancy_grid.occluded_occupancies.to(device)\n",
    "        agent_mask = scene.observed_state.agent_mask.to(device)\n",
    "\n",
    "        batch, length, width, time, _ = occupancy_grid_occupancies.shape\n",
    "        occupancy_grid_positions = occupancy_grid_positions.reshape(batch, length * width, 2)\n",
    "\n",
    "        #for tt in range(10):\n",
    "        for t in range(time):\n",
    "            #t = tt * 10\n",
    "            times = occupancy_grid_times[:, t].view(batch, 1, 1).expand(batch, length * width, 1)\n",
    "            positions = occupancy_grid_positions\n",
    "            estimated_occupancies, _ = occupancy_flow_network.estimate_occupancy(times, positions, road_map, agent_trajectories, agent_mask)\n",
    "            estimated_unoccluded_occupancies = estimated_occupancies[:, :, 0]\n",
    "            estimated_occluded_occupancues = estimated_occupancies[:, :, 1]\n",
    "\n",
    "            estimated_unoccluded_occupancies = estimated_unoccluded_occupancies.reshape(batch, length, width, 1)\n",
    "            ground_truth_unoccluded_occupancies = occupancy_grid_unoccluded_occupancies[:, :, :, t, :]\n",
    "\n",
    "            estimated_occluded_occupancues = estimated_occluded_occupancues.reshape(batch, length, width, 1)\n",
    "            ground_truth_occluded_occupancies = occupancy_grid_occluded_occupancies[:, :, :, t, :]\n",
    "\n",
    "            unoccluded_loss = criterion(estimated_unoccluded_occupancies, ground_truth_unoccluded_occupancies)\n",
    "            occluded_loss = criterion(estimated_unoccluded_occupancies, ground_truth_unoccluded_occupancies)\n",
    "            loss = 0.5 * unoccluded_loss + 0.5 * occluded_loss\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(occupancy_flow_network.parameters(), max_norm=1.0)\n",
    "            optim.step()\n",
    "\n",
    "        epoch_loss += loss\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    #epoch_loss /= NUM_SCENES\n",
    "    \n",
    "    #if epoch == 0 or (epoch + 1) % 100 == 0:\n",
    "    print(f'epoch {epoch+1} loss: {epoch_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_occupancies = []\n",
    "\n",
    "for scene in scenes:\n",
    "    road_map = scene.observed_state.road_map.to(device)\n",
    "    agent_trajectories = scene.observed_state.agent_trajectories.to(device)\n",
    "    occupancy_grid_positions = scene.occupancy_grid.positions.to(device)\n",
    "    occupancy_grid_times = scene.occupancy_grid.times.to(device)\n",
    "    occupancy_grid_occupancies = scene.occupancy_grid.unoccluded_occupancies.to(device)\n",
    "    agent_mask = scene.observed_state.agent_mask.to(device)\n",
    "\n",
    "    batch, length, width, time, _ = occupancy_grid_occupancies.shape\n",
    "    occupancy_grid_positions = occupancy_grid_positions.reshape(batch, length * width, 2)\n",
    "\n",
    "    for t in range(time):\n",
    "        times = occupancy_grid_times[:, t].view(batch, 1, 1).expand(batch, length * width, 1)\n",
    "        positions = occupancy_grid_positions\n",
    "        with torch.no_grad():\n",
    "            estimated_occupancy, _ = occupancy_flow_network.estimate_occupancy(times, positions, road_map, agent_trajectories, agent_mask)\n",
    "        #estimated_occluded_occupancies = occupancy_flow_network.estimate_occluded_occupancy(occupancy_grid_times, occupancy_grid_positions, road_map, agent_trajectories, agent_mask)\n",
    "\n",
    "        estimated_occupancy = estimated_occupancy[:, :, 0].reshape(batch, length, width, 1)\n",
    "        estimated_occupancies.append(estimated_occupancy)\n",
    "\n",
    "estimated_occupancies = torch.stack(estimated_occupancies, dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ed27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for scene in scenes:\n",
    "    count += 1\n",
    "    if count > MAX_SCENES_TO_RENDER:\n",
    "        break\n",
    "\n",
    "    road_map = scene.observed_state.road_map\n",
    "\n",
    "    anim = render_ground_truth_occupancy(road_map[0], estimated_occupancies[0].cpu(), occluded=False)\n",
    "    display(HTML(anim.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915ebf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_occupancies = []\n",
    "\n",
    "for road_map, agent_trajectories, _, _, _, _, occupancy_grid_positions, occupancy_grid_times, occupancy_grid_occupancies, occupancy_grid_occluded_occupancies, agent_mask, _ in scenes:\n",
    "    road_map = road_map.to(device)\n",
    "    agent_trajectories = agent_trajectories.to(device)\n",
    "    occupancy_grid_positions = occupancy_grid_positions.to(device)\n",
    "    occupancy_grid_times = occupancy_grid_times.to(device)\n",
    "    occupancy_grid_occupancies = occupancy_grid_occupancies.to(device)\n",
    "    occupancy_grid_occluded_occupancies = occupancy_grid_occluded_occupancies.to(device)\n",
    "    agent_mask = agent_mask.to(device)\n",
    "\n",
    "    batch, length, width, time, _ = occupancy_grid_occupancies.shape\n",
    "    occupancy_grid_positions = occupancy_grid_positions.reshape(batch, length * width, 2)\n",
    "\n",
    "    for t in range(time):\n",
    "        times = occupancy_grid_times[:, t].view(1, 1, 1).expand(1, length * width, 1)\n",
    "        positions = occupancy_grid_positions\n",
    "        with torch.no_grad():\n",
    "            estimated_occupancy, _ = occupancy_flow_network.estimate_occupancy(times, positions, road_map, agent_trajectories, agent_mask)\n",
    "        #estimated_occluded_occupancies = occupancy_flow_network.estimate_occluded_occupancy(occupancy_grid_times, occupancy_grid_positions, road_map, agent_trajectories, agent_mask)\n",
    "\n",
    "        estimated_occupancy = estimated_occupancy.reshape(batch, length, width, 1)\n",
    "        estimated_occupancies.append(estimated_occupancy)\n",
    "\n",
    "estimated_occupancies = torch.stack(estimated_occupancies, dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04806ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for road_map, _, _, _, _, _, _, _, _, _, _, _ in scenes:\n",
    "    count += 1\n",
    "    if count > MAX_SCENES_TO_RENDER:\n",
    "        break\n",
    "\n",
    "    anim = render_ground_truth_occupancy(road_map[0], estimated_occupancies[0].cpu(), occluded=False)\n",
    "    display(HTML(anim.to_jshtml()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeaeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_flow_network2 = OccupancyFlowNetwork(road_map_image_size=256, road_map_window_size=8, \n",
    "                                              trajectory_feature_dim=10, \n",
    "                                              embedding_dim=256, \n",
    "                                              flow_field_hidden_dim=256, flow_field_fourier_features=128).to(device)\n",
    "occupancy_flow_network2.train()\n",
    "\n",
    "optim = torch.optim.Adam(occupancy_flow_network2.parameters(), lr=1e-4, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=0.999)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "EPOCHS = 1000\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for road_map, agent_trajectories, _1, _2, _3, _4, occupancy_grid_positions, occupancy_grid_times, occupancy_grid_occupancies, occupancy_grid_occluded_occupancies, agent_mask, _ in scenes:\n",
    "        road_map = road_map.to(device)\n",
    "        agent_trajectories = agent_trajectories.to(device)\n",
    "        occupancy_grid_positions = occupancy_grid_positions.to(device)\n",
    "        occupancy_grid_times = occupancy_grid_times.to(device)\n",
    "        occupancy_grid_occupancies = occupancy_grid_occupancies.to(device)\n",
    "        occupancy_grid_occluded_occupancies = occupancy_grid_occluded_occupancies.to(device)\n",
    "        agent_mask = agent_mask.to(device)\n",
    "\n",
    "        batch, length, width, time, _ = occupancy_grid_positions.shape\n",
    "        occupancy_grid_positions = occupancy_grid_positions.reshape(batch, length * width, time, 2)\n",
    "        occupancy_grid_times = occupancy_grid_times.reshape(batch, length * width, time, 1)\n",
    "\n",
    "        for t in range(time):\n",
    "            times = occupancy_grid_times[:, :, t, :]\n",
    "            positions = occupancy_grid_positions[:, :, t, :]\n",
    "            estimated_occupancies, _ = occupancy_flow_network2.estimate_occupancy(times, positions, road_map, agent_trajectories, agent_mask)\n",
    "            #estimated_occluded_occupancies = occupancy_flow_network.estimate_occluded_occupancy(occupancy_grid_times, occupancy_grid_positions, road_map, agent_trajectories, agent_mask)\n",
    "\n",
    "            estimated_occupancies = estimated_occupancies.reshape(batch, length, width, 1)\n",
    "            ground_truth_occupancies = occupancy_grid_occupancies[:, :, :, t, :]\n",
    "\n",
    "            loss = criterion(estimated_occupancies, ground_truth_occupancies)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(occupancy_flow_network.parameters(), max_norm=1.0)\n",
    "            optim.step()\n",
    "\n",
    "        epoch_loss += loss\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_loss /= NUM_SCENES\n",
    "    \n",
    "    #if epoch == 0 or (epoch + 1) % 100 == 0:\n",
    "    print(f'epoch {epoch+1} loss: {epoch_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ecf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_occupancies2 = []\n",
    "\n",
    "for road_map, agent_trajectories, _, _, _, _, occupancy_grid_positions, occupancy_grid_times, occupancy_grid_occupancies, occupancy_grid_occluded_occupancies, agent_mask, _ in scenes:\n",
    "    road_map = road_map.to(device)\n",
    "    agent_trajectories = agent_trajectories.to(device)\n",
    "    occupancy_grid_positions = occupancy_grid_positions.to(device)\n",
    "    occupancy_grid_times = occupancy_grid_times.to(device)\n",
    "    occupancy_grid_occupancies = occupancy_grid_occupancies.to(device)\n",
    "    occupancy_grid_occluded_occupancies = occupancy_grid_occluded_occupancies.to(device)\n",
    "    agent_mask = agent_mask.to(device)\n",
    "\n",
    "    batch, length, width, time, _ = occupancy_grid_positions.shape\n",
    "    occupancy_grid_positions = occupancy_grid_positions.reshape(batch, length * width, time, 2)\n",
    "    occupancy_grid_times = occupancy_grid_times.reshape(batch, length * width, time, 1)\n",
    "\n",
    "    for t in range(time):\n",
    "        times = occupancy_grid_times[:, :, t, :]\n",
    "        positions = occupancy_grid_positions[:, :, t, :]\n",
    "        with torch.no_grad():\n",
    "            estimated_occupancy, _ = occupancy_flow_network2.estimate_occupancy(times, positions, road_map, agent_trajectories, agent_mask)\n",
    "        #estimated_occluded_occupancies = occupancy_flow_network.estimate_occluded_occupancy(occupancy_grid_times, occupancy_grid_positions, road_map, agent_trajectories, agent_mask)\n",
    "\n",
    "        estimated_occupancy = estimated_occupancy.reshape(batch, length, width, 1)\n",
    "        estimated_occupancies2.append(estimated_occupancy)\n",
    "\n",
    "estimated_occupancies2 = torch.stack(estimated_occupancies2, dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for road_map, _, _, _, _, _, _, _, _, _, _, _ in scenes:\n",
    "    count += 1\n",
    "    if count > MAX_SCENES_TO_RENDER:\n",
    "        break\n",
    "\n",
    "    anim = render_ground_truth_occupancy(road_map[0], estimated_occupancies2[0].cpu(), occluded=False)\n",
    "    display(HTML(anim.to_jshtml()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ofenv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
